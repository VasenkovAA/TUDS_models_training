{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91dfb60c-3c23-4d23-ab34-b5d21669bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, log_loss\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import EMNIST\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e0e437-4d2e-4202-8ba3-e8054082e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка параметров\n",
    "input_size = 784  # 28x28\n",
    "hidden_size1 = 500\n",
    "hidden_size2 = 250\n",
    "num_classes = 10\n",
    "num_epochs =15\n",
    "batch_size = 500\n",
    "learning_rate = 0.01\n",
    "save_model = True\n",
    "log_file_path = 'results/ResultsLog.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ebf6d1-2683-45b1-b76f-5d50a81c0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и нормализация данных EMNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = EMNIST(root='../data', split='byclass', train=True, transform=transform, download=True)\n",
    "test_dataset = EMNIST(root='../data', split='byclass', train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ee3802-bce4-4bb7-b51e-3319a1900f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=62):\n",
    "        super(ImprovedConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(128*3*3, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0be91f5-4f41-4a26-a16a-7bbc894127ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "model = ImprovedConvNet(num_classes=62).to(device)\n",
    "\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ec7970-3510-48cc-9f1f-faf82ef8affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация для графиков\n",
    "loss_ce_list = {'train': [], 'val': []}\n",
    "accuracy_list = {'train': [], 'val': []}\n",
    "precision_list = {'train': [], 'val': []}\n",
    "recall_list = {'train': [], 'val': []}\n",
    "f1_list = {'train': [], 'val': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d49c539-f987-485b-a232-caedd869d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка существования файла логирования и создание нового\n",
    "if not os.path.exists(log_file_path):\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        log_file.write(\"Test No\\tAccuracy\\tPrecision\\tRecall\\tF1-score\\tROC AUC\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527e9f15-2700-4e25-b2b3-5f7e2fad46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Функция для вычисления метрик\n",
    "def compute_metrics(loader, model):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31908bbe-2219-48b5-b676-c6f3845648c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обновления и сохранения графиков\n",
    "def update_plots(loss_ce_list, accuracy_list, precision_list, recall_list, f1_list, epoch, save_path='../temp/training_progress.png'):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    \n",
    "    # График функции потерь CrossEntropy\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(loss_ce_list['train'], label='Train CrossEntropy Loss')\n",
    "    plt.plot(loss_ce_list['val'], label='Validation CrossEntropy Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('CrossEntropy Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # График точности\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(accuracy_list['train'], label='Train Accuracy')\n",
    "    plt.plot(accuracy_list['val'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # График Precision\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(precision_list['train'], label='Train Precision')\n",
    "    plt.plot(precision_list['val'], label='Validation Precision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    # График Recall\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.plot(recall_list['train'], label='Train Recall')\n",
    "    plt.plot(recall_list['val'], label='Validation Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.title('Recall')\n",
    "    plt.legend()\n",
    "\n",
    "    # График F1-score\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.plot(f1_list['train'], label='Train F1-score')\n",
    "    plt.plot(f1_list['val'], label='Validation F1-score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1-score')\n",
    "    plt.title('F1-score')\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    # Номер теста\n",
    "    plt.figtext(0.5, 0.05, f'Test No: {get_test_number(log_file_path)}', wrap=True, horizontalalignment='center', fontsize=12)\n",
    "\n",
    "    # Добавление информации о модели\n",
    "    plt.suptitle(f'Loss Function: CE Optimizer: SGD, LR: {learning_rate}, Epochs: {num_epochs}, Batch Size: {batch_size}')\n",
    "    \n",
    "    # Информация о слоях модели\n",
    "    model_info = (\n",
    "        f\"Model Architecture:\\n\"\n",
    "        f\"Input Layer: {input_size} neurons\\n\"\n",
    "        f\"Hidden Layer 1: {hidden_size1} neurons with Batch Normalization and ReLU activation\\n\"\n",
    "        f\"Hidden Layer 2: {hidden_size2} neurons with Batch Normalization and ReLU activation\\n\"\n",
    "        f\"Output Layer: {num_classes} neurons\"\n",
    "    )\n",
    "    \n",
    "    plt.figtext(0.5, -0.1, model_info, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    \n",
    "    # Сохранение графиков в файл\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce680baf-f894-4edc-bf88-e954ee8f8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для получения номера теста\n",
    "def get_test_number(log_file_path):\n",
    "    with open(log_file_path, 'r') as log_file:\n",
    "        lines = log_file.readlines()\n",
    "        return len(lines) - 1  # Исключаем заголовок\n",
    "\n",
    "# Функция для сохранения модели\n",
    "def save_model(model, test_number):\n",
    "    model_path = f'model_{test_number}.ckpt'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2f3d59-adb9-46c1-b0a1-5ff4377c144c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m loss_ce \u001b[38;5;241m=\u001b[39m criterion_ce(outputs, labels)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss_ce\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m running_loss_ce \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_ce\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss_ce = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss_ce = criterion_ce(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_ce.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss_ce += loss_ce.item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss CE: {loss_ce.item():.4f}')\n",
    "    \n",
    "    # Тестирование модели\n",
    "    model.eval()\n",
    "    \n",
    "    # Метрики для обучающего набора данных\n",
    "    train_accuracy, train_precision, train_recall, train_f1 = compute_metrics(train_loader, model)\n",
    "    # Метрики для валидационного набора данных\n",
    "    val_accuracy, val_precision, val_recall, val_f1 = compute_metrics(test_loader, model)\n",
    "    \n",
    "    avg_loss_ce = running_loss_ce / total_step\n",
    "    \n",
    "    loss_ce_list['train'].append(avg_loss_ce)\n",
    "    accuracy_list['train'].append(train_accuracy)\n",
    "    precision_list['train'].append(train_precision)\n",
    "    recall_list['train'].append(train_recall)\n",
    "    f1_list['train'].append(train_f1)\n",
    "\n",
    "    loss_ce_list['val'].append(avg_loss_ce)\n",
    "    accuracy_list['val'].append(val_accuracy)\n",
    "    precision_list['val'].append(val_precision)\n",
    "    recall_list['val'].append(val_recall)\n",
    "    f1_list['val'].append(val_f1)\n",
    "    \n",
    "    # Обновление и сохранение графиков (функция update_plots должна быть определена ранее)append\n",
    "    update_plots(loss_ce_list, accuracy_list, precision_list, recall_list, f1_list, epoch)\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013e841-c696-4e09-8d60-889d95c8d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись результатов тестов в файл логирования\n",
    "with open(log_file_path, 'a') as log_file:\n",
    "    log_file.write(f\"{get_test_number(log_file_path)}\\t{val_accuracy:.4f}\\t{val_precision:.4f}\\t{val_recall:.4f}\\t{val_f1:.4f}\\t\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c9517-483a-4993-8a6d-c9e72d8708b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение финальных графиков\n",
    "update_plots(loss_ce_list, accuracy_list, precision_list, recall_list, f1_list, num_epochs-1, f'results/test_{get_test_number(log_file_path)}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45dd07-fe76-4ede-9c03-556191e98c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для сохранения модели\n",
    "def save_model(model, test_number):\n",
    "    model_path = f'models/model_{test_number}.ckpt'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    return model_path\n",
    "\n",
    "if save_model:\n",
    "    test_number = get_test_number(log_file_path)\n",
    "    model_path = save_model(model, test_number)\n",
    "    print(f\"Model saved as {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c15c21-6c67-49c4-80c4-6282c1710294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
